# How I am learning Artificial Intelligence in 2024
- Study `Natural Language Processing`
- Apply knowledge to projects

## Improvements from '2023 Learning Experience'
Details: [last year's Computer Vision](https://github.com/ajinkyakolhe112/Mastering-Deep-Learning-in-2023)
Things I am improving
  - Focus on high level libraries like `transformers` and `diffusers` over `pytorch`
    - Advantage: Few lines to have end to end pipeline
    - Advantage: Getting to solution quickly instead of 2 weeks of implementing from scratch
  - Do more Kaggle competitions compared to courses.    (10 courses & 3 competitions last year, Aiming for 10+ competitions this year)
  - Continue coding in pytorch, build code cookbook for experimentation
  - Visualize model internals to understand it better.  (Didn't do this part last year)
  - Understand maths aspect of neural networks.         (Didn't do this part last year.)
  
## NLP - NLP Landscape's two entry paths
- NLP Landscape has two entry points, one slow, long & easier path & other short but steep path
  - Long & Slow path:   DL Basics -> Simple NN -> CNN -> RNN -> LSTM -> Word2Vec -> Attention -> LLMs
  - Short & Steep path: DL Basics -> **Attention is all you need** -> LLMs
    - Everything in NLP & CV is building on top of this single paper. Highest citations, higest used architecture, is most varied kinds of problems.
    - Understand this thoroughly, because everything builds on this

## Quarter 1 - Things Learned

### NLP - 5 STAR RESOURCES
|   Type                |    Details                        | Progress                            |
| ---------             | ----------                        | --------------------------------    |
1: Course               | Huggingface NLP                   | ![](https://geps.dev/progress/100)  |
2: Kaggle Competition   | Disaster Tweet Classification     | ![](https://geps.dev/progress/100)  |
3: Research Paper       | Attention is all you need         | ![](https://geps.dev/progress/100)  |
4: Research Paper       | One Model to learn them all       | ![](https://geps.dev/progress/100)  |
5: Youtube Video        | 3Blue1Brown: Attention in transformers, visually explained            | ![](https://geps.dev/progress/100)  |
6: Youtube Video        | 3Blue1Brown: But what is a GPT? Visual intro to transformers          | ![](https://geps.dev/progress/100)  |
7: Youtube Video        | Campus X: Epic History of Large Language Models                       | ![](https://geps.dev/progress/100)  |
8: Youtube Video        | Campus X: Self Attention          | ![](https://geps.dev/progress/100)  |
9: Youtube Video        | Campus X: Attention               | ![](https://geps.dev/progress/100)  |

### Computer Vision - 5 STAR RESOURCES
|   Type                |    Details                        | Progress                            |
| ---------             | ----------                        | --------------------------------    |
1: Course               | Huggingface timm                    | ![](https://geps.dev/progress/100)  |
2: Course               | Huggingface diffusers               | ![](https://geps.dev/progress/100)  |
3: Course               | Huggingface Community Vision Course | ![](https://geps.dev/progress/100)  |
4: Course               | Zero to Mastery Tensorflow          | ![](https://geps.dev/progress/100)  |