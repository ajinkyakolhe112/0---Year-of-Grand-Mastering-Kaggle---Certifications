# How I am learning Artificial Intelligence in 2024
- Goal `Natural Language Processing`
  - & continue learning Image Generation with `Diffusers`
- Apply knowledge to projects

### Improvements from '2023 Learning Experience'
Details: [last year's Computer Vision](https://github.com/ajinkyakolhe112/Mastering-Deep-Learning-in-2023)
Things I am improving
  - Focus on high level libraries like `transformers` and `diffusers` over `pytorch`
    - Advantage: Few lines to have end to end pipeline
    - Advantage: Getting to solution quickly instead of 2 weeks of implementing from scratch
  - Do more Kaggle competitions compared to courses.    (10 courses & 3 competitions last year, Aiming for 10+ competitions this year)
  - Continue coding in pytorch, build code cookbook for experimentation
  - Visualize model internals to understand it better.  (Didn't do this part last year)
  - Understand maths aspect of neural networks.         (Didn't do this part last year.)

### Lessons Learned in 2024
- Landscape of standard LLM architectures, once memorized, a lot of problems become a lot simpler
- Projects are the best way to learn. Deep Learning is a field of experimentation, not theoratical field. That is why projects are the best way to learn.
- State of the art models require bigger GPUs. Free T4 GPU has 16GB of VRAM, can only store 8 Billion parameter model. 
- LLama models are the best models open source AI models, which are as commercial AI models like GPT-4 and Google AI

### Remaining Study Topics
- Research Papers on diffusion models & transformer models optimizations
- Reinforcement Learning
- Custom Dataset building & fine tuning models
- Model Optimization 

## NLP Study Plan
NLP Landscape's two entry paths. One slow, long & easier path & other short but steep path
  - Long & Slow path:   DL Basics -> Simple NN -> CNN -> RNN -> LSTM -> Word2Vec -> Attention -> LLMs
  - Short & Steep path: DL Basics -> **Attention is all you need** -> LLMs
    - Everything in NLP & CV is building on top of this single paper. Highest citations, highest used architecture, is most varied kinds of problems.
    - Understand this thoroughly, because everything builds on this

## Quarter 1 - Things Learned

### NLP - 5 STAR RESOURCES
|   Type                |    Details                        | Progress                            |
| ---------             | ----------                        | --------------------------------    |
1: Course               | Huggingface NLP                   | ![](https://geps.dev/progress/100)  |
2: Kaggle Competition   | Disaster Tweet Classification     | ![](https://geps.dev/progress/100)  |
3: Research Paper       | Attention is all you need         | ![](https://geps.dev/progress/100)  |
4: Research Paper       | One Model to learn them all       | ![](https://geps.dev/progress/100)  |
5: Youtube Video        | 3Blue1Brown: Attention in transformers, visually explained            | ![](https://geps.dev/progress/100)  |
6: Youtube Video        | 3Blue1Brown: But what is a GPT? Visual intro to transformers          | ![](https://geps.dev/progress/100)  |
7: Youtube Video        | Campus X: Epic History of Large Language Models                       | ![](https://geps.dev/progress/100)  |
8: Youtube Video        | Campus X: Self Attention          | ![](https://geps.dev/progress/100)  |
9: Youtube Video        | Campus X: Attention               | ![](https://geps.dev/progress/100)  |
11: Udemy Course        | LLM Application Dev with Langchain| ![](https://geps.dev/progress/10)   | 

### Computer Vision - 5 STAR RESOURCES
|   Type                |    Details                        | Progress                            |
| ---------             | ----------                        | --------------------------------    |
1: Course               | Huggingface timm                    | ![](https://geps.dev/progress/100)  |
2: Course               | Huggingface diffusers               | ![](https://geps.dev/progress/100)  |
3: Course               | Huggingface Community Vision Course | ![](https://geps.dev/progress/100)  |
4: Course               | Zero to Mastery Tensorflow          | ![](https://geps.dev/progress/100)  |

### 1.2. Kaggle Competitions - 3 Competitions


| Competition                                 | Progress                           |
| ---------------------------------------     | ------------------------------------ |
| Cats vs Dogs - End to End Pipeline          | ![](https://geps.dev/progress/100) |
| 10 Small Objects Recognition(CIFAR10)       | ![](https://geps.dev/progress/100) |
| Imagenet Classification                     | ![](https://geps.dev/progress/100) |


### (Pivot to Projects) Projects -> Applications for a Industry
- Studying Industries as application of Artificial Intelligence. (Interesting, Relevant for Future industries)
  - I also love **Video Games**. Any application in video game building pipeline. Found out in further research, Video Game Industry is bigger than Books + Movies + Tv Series + Music.
  - **Augmented Reality**. AR Glasses in less than 50k, cheaper than smartphone & TV.
  - I love **books**. So projects / industries around books would be - Book to Illustrated Images or Book's adaption to Film / Tv Series. 

- Learning `Unreal Engine 5` for `Video Games`
  - [ ] Future: Build `Video Game` for `Mahabharat`
  - [ ] Future: Build `Video Game` like `Age of Empires for India`
- Studying `Screenplays`
  - I have loved `Dune`. So studied `Screenplay` of Dune as well
  - For `Film making of Harry Potter`
- `Harry Potter` - immersive book or video game or a film

### Certifications
- [ ] Tensorflow Certification Exam (Failed)
- [x] Google Cloud Data Engineer Certification (Passed)
- [x] Google Cloud Architect Certification     (Passed)

### Corporate Trainings
1. Data Engineering for `MTech Students` for `LTI Mindtree`
2. Application Development for `MTech Students` for `LTI Mindtree`
3. How Developers can learn Artificial Intelligence - a `DevRel Talk`
